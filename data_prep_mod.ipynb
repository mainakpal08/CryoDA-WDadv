{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import mrcfile\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training data - part 1\r\n",
      "\r\n",
      "#### subtomogram, density map, and lables(.json)\r\n",
      "#### All training data: 10 types, 500 each, 5000 total\r\n",
      "\r\n",
      "part 1: 4 types of macromolecules, 500 each (2000 total)\r\n",
      " \r\n",
      "part 2: 6 types of macromolecules, 500 each (3000 total)\r\n",
      "\r\n",
      "\r\n",
      "#### 1. subtomogram_mrc \r\n",
      "filenames: tomotarget*.mrc, * = 0,1,2,...,4999\r\n",
      "\r\n",
      "This is our input data!\r\n",
      "The subtomogram of a single macromolecule and some part of its neighbors. \r\n",
      "The size is 32 * 32 * 32.\r\n",
      "\r\n",
      ".mrc file could be open with python package: mrcfile. \r\n",
      "It could be visualized using software: Chimera (https://www.cgl.ucsf.edu/chimera/). This software is very easy to use.\r\n",
      "\r\n",
      "#### 2. subtomogram_png \r\n",
      "filenames: tomotarget*.png, * = 0,1,2,...,4999\r\n",
      "\r\n",
      "the slices of a subtomogram. Sice the size of a subtomogram is 32^3, there are 32 subfigures in each image.\r\n",
      "\r\n",
      "This is to help understand the content in the subtomogram.\r\n",
      "\r\n",
      "#### 3. json:\r\n",
      "\r\n",
      "##### there two types of json files in json folder:\r\n",
      "\r\n",
      "filenames: target*.json: this is the label for the simulated target data. (you may need to focus on these files)\r\n",
      "\r\n",
      "filenames: packing*.json: ignor these files. They are used to guide the simulation, but it's not the label for the simulated data.\r\n",
      "\r\n",
      "\r\n",
      "##### detailed information for target*.json: \r\n",
      "\r\n",
      "The label of the corresponding subtomogram. The file is in the following format:\r\n",
      "\r\n",
      "{\"loc\": [5, 4, -2], \"rotate\": [-2.7956930634210506, 1.1126108053114863, -1.2948702875352103], \"name\": \"1bxn\"}\r\n",
      "\r\n",
      "The location parameter is the relative position to the center. The positive direction is the direction in which the array subscript values increase.\r\n",
      "\r\n",
      "The meaning of the rotate parameter is the angle that the protein rotates along the coordinate axis in ZYZ order. For more details, search \"Euler angle\".\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "#### 4. densitymap_mrc\r\n",
      "\r\n",
      "filenames: packtarget*.mrc, * = 0,1,2,...,4999\r\n",
      "\r\n",
      "density map: the Grayscale map, could be regarded as the ground truth of segmentation task\r\n",
      "\r\n",
      "#### 5. densitymap_png\r\n",
      "\r\n",
      "filenames: packtarget*.png, * = 0,1,2,...,4999\r\n",
      "\r\n",
      "the slices of a density map. Sice the size of a density map is 32^3, there are 32 subfigures in each image.\r\n",
      "\r\n",
      "This is to help understand the content in the density map.\r\n",
      "\r\n",
      "#### 3. including the following macromolecules:\r\n",
      "\r\n",
      "######(training data part 1)\r\n",
      "\r\n",
      "0-499 \t    1bxn,\r\n",
      "\r\n",
      "500-999\t    1f1b,\r\n",
      "\r\n",
      "1000-1499\t1yg6,\r\n",
      "\r\n",
      "1500-1999\t2byu,\r\n",
      "\r\n",
      "######(training data part 2)\r\n",
      "\r\n",
      "2000-2499\t3gl1,\r\n",
      "\r\n",
      "2500-2999\t4d4r,\r\n",
      "\r\n",
      "3000-3499\t6t3e,\r\n",
      "\r\n",
      "3500-3999\t2ldb,\r\n",
      "\r\n",
      "4000-4499\t2h12,\r\n",
      "\r\n",
      "4500-4999\t3hhb."
     ]
    }
   ],
   "source": [
    "!cat readme.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'1bxn': 0, \n",
    "              '1f1b': 1,\n",
    "              '1yg6': 2,\n",
    "              '2byu': 3, \n",
    "              '3gl1': 4,\n",
    "              '4d4r': 5,\n",
    "              '6t3e': 6,\n",
    "              '2ldb': 7,\n",
    "              '2h12': 8,\n",
    "              '3hhb': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path):\n",
    "    with mrcfile.open(path, 'r') as m:\n",
    "        header = m.header\n",
    "        data = m.data\n",
    "        assert data.ndim == 3  \n",
    "        data = data.transpose([2, 1, 0])    \n",
    "\n",
    "    return {'header':header, 'data': data}\n",
    "\n",
    "def read_mrcdata(path):\n",
    "    return read(path)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsondata(x):\n",
    "    with open(x) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    c_loc = data['loc']\n",
    "    label = data['name']\n",
    "    angle = data['rotate']\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.array(range(0,2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(idx, columns=['idx'])\n",
    "df['subtomogram_path'] = df['idx'].map(lambda x: './subtomogram_mrc/tomotarget%s.mrc' % x)\n",
    "df['densitymap_path'] = df['idx'].map(lambda x: './densitymap_mrc/packtarget%s.mrc' % x)\n",
    "df['label_path'] = df['idx'].map(lambda x: './json/target%s.json' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>subtomogram_path</th>\n",
       "      <th>densitymap_path</th>\n",
       "      <th>label_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>./subtomogram_mrc/tomotarget0.mrc</td>\n",
       "      <td>./densitymap_mrc/packtarget0.mrc</td>\n",
       "      <td>./json/target0.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>./subtomogram_mrc/tomotarget1.mrc</td>\n",
       "      <td>./densitymap_mrc/packtarget1.mrc</td>\n",
       "      <td>./json/target1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>./subtomogram_mrc/tomotarget2.mrc</td>\n",
       "      <td>./densitymap_mrc/packtarget2.mrc</td>\n",
       "      <td>./json/target2.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>./subtomogram_mrc/tomotarget3.mrc</td>\n",
       "      <td>./densitymap_mrc/packtarget3.mrc</td>\n",
       "      <td>./json/target3.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>./subtomogram_mrc/tomotarget4.mrc</td>\n",
       "      <td>./densitymap_mrc/packtarget4.mrc</td>\n",
       "      <td>./json/target4.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                   subtomogram_path                   densitymap_path  \\\n",
       "0    0  ./subtomogram_mrc/tomotarget0.mrc  ./densitymap_mrc/packtarget0.mrc   \n",
       "1    1  ./subtomogram_mrc/tomotarget1.mrc  ./densitymap_mrc/packtarget1.mrc   \n",
       "2    2  ./subtomogram_mrc/tomotarget2.mrc  ./densitymap_mrc/packtarget2.mrc   \n",
       "3    3  ./subtomogram_mrc/tomotarget3.mrc  ./densitymap_mrc/packtarget3.mrc   \n",
       "4    4  ./subtomogram_mrc/tomotarget4.mrc  ./densitymap_mrc/packtarget4.mrc   \n",
       "\n",
       "            label_path  \n",
       "0  ./json/target0.json  \n",
       "1  ./json/target1.json  \n",
       "2  ./json/target2.json  \n",
       "3  ./json/target3.json  \n",
       "4  ./json/target4.json  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subtom'] = df['subtomogram_path'].map(read_mrcdata)\n",
    "df['density'] = df['densitymap_path'].map(read_mrcdata)\n",
    "df['class'] = df['label_path'].map(read_jsondata)\n",
    "\n",
    "df['label'] = df['class'].map(label_dict)\n",
    "df['label'] = df.label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    500\n",
       "2    500\n",
       "1    500\n",
       "0    500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class = np.array_split(df, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train = []\n",
    "source_test = []\n",
    "target_train = []\n",
    "target_test = []\n",
    "\n",
    "for i in range(4):\n",
    "    class_train, class_test = train_test_split(all_class[i], test_size=0.1)\n",
    "    train_split = np.array_split(class_train, 2)\n",
    "    test_split = np.array_split(class_test, 2)\n",
    "    \n",
    "    source_train.append(train_split[0])\n",
    "    source_test.append(test_split[0])\n",
    "    target_train.append(train_split[1])\n",
    "    target_test.append(test_split[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train = pd.concat(source_train)\n",
    "source_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_test = pd.concat(source_test)\n",
    "source_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = pd.concat(target_train)\n",
    "target_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test = pd.concat(target_test)\n",
    "target_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_as_hdf(out_path, out_df):\n",
    "    with h5py.File(out_path, 'w') as h:\n",
    "        for k, arr_dict in tqdm(out_df.to_dict().items()): \n",
    "            try:\n",
    "                s_data = np.stack(arr_dict.values(), 0)\n",
    "\n",
    "                try:\n",
    "                    h.create_dataset(k, data = s_data, compression = 'gzip')\n",
    "                except TypeError as e: \n",
    "                    try:\n",
    "                        h.create_dataset(k, data = s_data.astype(np.string_))\n",
    "                    except TypeError as e2: \n",
    "                        print('%s could not be added to hdf5, %s' % (k, repr(e), repr(e2)))\n",
    "\n",
    "            except ValueError as e:\n",
    "                print('%s could not be created, %s' % (k, repr(e)))\n",
    "                all_shape = [np.shape(x) for x in arr_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/mpal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \"\"\"\n",
      "100%|██████████| 8/8 [00:08<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "write_df_as_hdf('source_train.h5', source_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/mpal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \"\"\"\n",
      "100%|██████████| 8/8 [00:00<00:00, 12.86it/s]\n"
     ]
    }
   ],
   "source": [
    "write_df_as_hdf('source_test.h5', source_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/mpal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \"\"\"\n",
      "100%|██████████| 8/8 [00:05<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "write_df_as_hdf('target_train.h5', target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/mpal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \"\"\"\n",
      "100%|██████████| 8/8 [00:00<00:00, 13.21it/s]\n"
     ]
    }
   ],
   "source": [
    "write_df_as_hdf('target_test.h5', target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('source_train.h5', 'r') as scan_h5:\n",
    "    source_train_subtom = scan_h5['subtom'][:]\n",
    "    source_train_label = scan_h5['label'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_train_subtom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class opt:\n",
    "    train_path = 'source_train.h5'\n",
    "    test_path = 'source_test.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-432a98deb1ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA_LOADER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# of training samples: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/target/training data part 1/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "data = utils.DATA_LOADER(opt)\n",
    "print(\"# of training samples: \", data.ntrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
